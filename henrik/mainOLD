#!/usr/bin/env python3

import cv2
import numpy as np
import time
import os
import math
import sys
import gi
from datetime import datetime, timedelta
from multiprocessing import *
import copy

#from paramiko import SSHClient
#from scp import SCPClient

gi.require_version("Tcam", "0.1")
gi.require_version("Gst", "1.0")

from gi.repository import Tcam, Gst

class Queue:
	def __init__(self):
		self.items = []

	def isEmpty(self):
		return self.items == []

	def enqueue(self, item):
		self.items.insert(0,item)

	def dequeue(self):
		return self.items.pop()

	def size(self):
		return len(self.items)

#For køen
class VideoObj(object):
	name = ""
	finished = False
	def __init__(self, timestamp, status):
		self.name = timestamp
		self.finished = status

class VideoArrayObject(object):
		start = 0.0
		stop = 0.0
		def __init__(self, name, startT, stopT):
			self.name = name
			self.start = startT
			self.stop = stopT

CompletedVideoQueue = Queue()
detectionPhase = False
detectionArray = []
detectionAmount = 0
video = ""
videoName = ""
startTime = 0.0
stopTime = 0.0
frameNumber = 0

def getSettings():
	global settings
	f = open("config.txt", "r")
	settings = []
	
	for line in f:
		settings.append(line.strip("\n"))
	f.close()
	# 0: format, 1: fps, 2: sekund før hendelse, 3: sekund etter hendelse, 4: piksel detect min, 5: piksel detect maks, 6: tekst overlay

def read():
	global videoName
	video = videoName
	datetime_object = datetime.strptime(video, "%d-%m-%Y_%H-%M-%S")

	capture = cv2.VideoCapture("../Videoer/" + video + ".mp4")
	mask = cv2.imread("mask.png")

	grayMask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
	retvalMask, thresholdMask = cv2.threshold(grayMask, 0, 255, cv2.THRESH_BINARY_INV)
	
	frameNumber = 0
	while(capture.isOpened()):
		ret, frame = capture.read()
		
		if ret == False:
			break
		
		detection(analyse(frame, frameNumber, datetime_object, thresholdMask))
		frameNumber += 1

	capture.release()
	cv2.destroyAllWindows()
	
	print("ferdig read")
	trim()
	print("ferdig trim")

def analyse(frame, frameNumber, datetime_object, thresholdMask):
	global frameDetect
	frameDetect = frameNumber
	global frameSave
	global frameSaveMarked
	frameSaveMarked = copy.deepcopy(frame)
	global frameTime
	
	hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
	#cv2.imshow("HSV Image", hsv)
	#cv2.waitKey(1)
	
	hue ,saturation ,value = cv2.split(hsv)
	#cv2.imshow('Saturation Image',value)
	#cv2.waitKey(1)
	
	grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	
	#teste grayFrame, hue, saturation og value :: første parameter
	#50 funker bra, 20 litt lavt? :: andre parameter
	retval, thresholded = cv2.threshold(grayFrame, 30, 255, cv2.THRESH_BINARY)

	medianFiltered = cv2.medianBlur(thresholded,3)

	_, contours, hierarchy = cv2.findContours(medianFiltered, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

	contour_list = []
	for contour in contours:
		area = cv2.contourArea(contour)
		if area > 100:
			contour_list.append(contour)
	
	#cv2.drawContours(frame, contour_list,  -1, (0,0,255), 2)
	#cv2.imshow('Objects Detected',frame)
	#cv2.waitKey(1)
	
	if not contour_list:
		return 0
	else:
		frameSaveMarked = cv2.drawContours(frameSaveMarked, contour_list,  -1, (0,0,255), 2)
		frameSave = frame
		
		frameTime = datetime_object + timedelta(seconds=frameNumber / 30)
		
		return 1
	'''
	grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	retval, threshold = cv2.threshold(grayFrame, 100, 255, cv2.THRESH_BINARY)
	
	maskMultiply = cv2.bitwise_and(threshold, thresholdMask)
	
	params = cv2.SimpleBlobDetector_Params()
	#params.minThreshold = 0
	#params.maxThreshold = 260
	params.filterByColor = False
	params.blobColor = 255
	params.filterByArea = True
	params.minArea = 20
	params.maxArea = 3000
	params.filterByCircularity = False
	params.filterByConvexity = False
	params.filterByInertia = False

	detector = cv2.SimpleBlobDetector_create(params)
	keypoints = detector.detect(maskMultiply)
	
	cv2.imshow("faen", threshold)
	cv2.waitKey(1)
	
	if not keypoints:
		return 0
	else:
		frameSaveMarked = cv2.drawKeypoints(frame, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
		
		frameTime = datetime_object + timedelta(seconds=frameNumber / 30)

		return 1
	'''
def detection(isDetect):
	global detectionPhase
	global startTime
	global stopTime
	global frameDetect
	global videoName
	global frameSave
	global frameSaveMarked
	global frameTime

	if isDetect == 1:
		if detectionPhase == False:
			print("!!!!!!!!!!!!!!!! DETECTION!!!!!!!!!!!")
			startTime = frameDetect
			detectionPhase = True
			cv2.imwrite("../Detections/Pictures/" + str(frameTime.strftime("%d-%m-%Y_%H-%M-%S")) + ".jpg", frameSave, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
			cv2.imwrite("../Detections/Pictures/" + str(frameTime.strftime("%d-%m-%Y_%H-%M-%S")) + "_marked.jpg", frameSaveMarked, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
		elif detectionPhase == True:
			print("Currently in detectionPhase, not storing a new startTrim")
			
	else:
		if detectionPhase == False:
			print("No detection")#do nothing
		
		elif detectionPhase == True:
			stopTime = frameDetect
			detectionPhase = False
			detectionArray.append(VideoArrayObject(videoName, startTime, stopTime))
			
def record():
	global videoName
	currentTime = datetime.now().strftime("%d-%m-%Y_%H-%M-%S")
	obj = VideoObj(currentTime, False)
	
	Gst.init(sys.argv)
	
	pipeline = Gst.Pipeline.new()
	
	filmDuration = 5 #sekunder
	
	if settings[1] == '15':
		framerate = '15/1'
	elif settings[1] == '7.5':
		framerate = '15/2'
	elif settings[1] == '3.75':
		framerate = '15/3'
	else:
		framerate = '30/1'
	
	pipeline = Gst.parse_launch('tcamsrc num-buffers=' + str((filmDuration * 30)) +' serial=4810628 '
				+ '! tcamautoexposure '
				+ '! tcamwhitebalance '
				+ '! tcamautofocus '
				+ '! video/x-bayer,format=bggr,width=1024,height=768,framerate=' + framerate
				+ '! capssetter join=false caps="video/x-bayer,format=gbrg" '
				+ '! bayer2rgb '
				#+ '! clockoverlay time-format="%d/%m/%Y %H:%M:%S" text="' + settings[6] + '" valignment=bottom xpad=0 ypad=0 font-desc="sans, 6" '
				+ '! videoconvert '
				+ '! omxh264enc '
				+ '! mp4mux '
				+ '! filesink location=../Videoer/' + currentTime + '.mp4 ')

	pipeline.set_state(Gst.State.PLAYING)
	
	time.sleep(filmDuration + 0.5)

	pipeline.set_state(Gst.State.NULL)
	
	print("Videoen er ferdiglagd, setter status = True og objektet blir lagt til i CompletedVideoQueue")
	setattr(obj, 'finished', 'True')
	videoName = currentTime
	CompletedVideoQueue.enqueue(obj)

def trim():
	if not CompletedVideoQueue.isEmpty():
		print("Fant video")
		
		global settings
		global videoName
		global frameNumber
		video = CompletedVideoQueue.dequeue() #Alle videoer som ligger i denne er ferdig behandlet.
		videoName = video.name
		
		for detection in detectionArray:
			print("Navn:",detection.name,", starttidspunkt:",detection.start,", stopptidspunkt:",detection.stop)
			
			datetime_object = datetime.strptime(videoName, "%d-%m-%Y_%H-%M-%S")
			filename = datetime_object + timedelta(seconds=detection.start / 30)
			
			capture = cv2.VideoCapture("../Videoer/" + str(videoName) + ".mp4")
			#fourcc = cv2.VideoWriter_fourcc(*'X264')
			out = cv2.VideoWriter("../Detections/Trims/" + str(filename.strftime("%d-%m-%Y_%H-%M-%S")) + ".mp4", 0x00000021, 30.0, (1024,768))

			count = 0
			while(capture.isOpened()):
				ret, frame = capture.read()
				
				if ret == False:
					break
				
				#muligens juster til 60 på begge
				if(count >= detection.start and count <= detection.stop):
					out.write(frame)
					
				count += 1
				
			capture.release()
			out.release()
			cv2.destroyAllWindows()
		
		#upload()
		'''
		os.system("rm -r ../Videoer/" + str(videoname) + ".mp4")
		os.system("rm -v ../Detections/Pictures/*")
		os.system("rm -v ../Detections/Trims/*")
		'''
		
		####TODO: (def?)Reset alle variabler som f.eks. blir ++'et. Ex: frameNumber
		
		#for trim in os.listdir("home/nvidia/Bachelor/Trims"):
			#TODO Send over til Hessdalen.no MathiasCode?

def upload():
	ssh = SSHClient()
	ssh.load_system_host_keys()
	ssh.connect("hessdalen.hiof.no")
	
	scp = SCPClient(ssh.get_transport())

	scp.put("test.txt", "test2.txt")

	scp.close()

if __name__ == "__main__":
	getSettings()
	
	record()
	read()
	
	'''
	while(True):
		recordProcess = Process(target=record)
		readProcess = Process(target=read)
		
		recordProcess.start()
		readProcess.start()
		recordProcess.join()
		readProcess.join()
		
		recordProcess.terminate()
		readProcess.terminate()
		
		time.sleep(10)
	'''
