#!/usr/bin/env python3

import cv2
import numpy as np
import time
import os
import math
import sys
import gi
from datetime import datetime, timedelta
from multiprocessing import *
import subprocess
import copy

gi.require_version("Tcam", "0.1")
gi.require_version("Gst", "1.0")

from gi.repository import Tcam, Gst

detectionPhase = False
filmDuration = 10 #sekunder
filepath = "/home/nvidia/Bachelor/"

def getSettings():
	global filepath
	
	f = open(filepath + "config.txt", "r")
	
	currentLine = 0
	for line in f:
		settings[currentLine] = line.strip("\n")
		currentLine += 1
	f.close()
	# 0: format, 1: fps, 2: sekund før hendelse, 3: sekund etter hendelse, 4: piksel detect min, 5: piksel detect maks, 6: tekst overlay
	
	mask = cv2.imread(filepath + "mask.png")
	grayMask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
	retvalMaskTemp, thresholdMaskTemp = cv2.threshold(grayMask, 0, 255, cv2.THRESH_BINARY_INV)
	thresholdMask.value = thresholdMaskTemp
	
def record():
	global filepath
	
	while(True):
		currentTime = datetime.now().strftime("%d-%m-%Y_%H-%M-%S")
		if settings[1] == '15':
			framerate = '15/1'
		elif settings[1] == '7.5':
			framerate = '15/2'
		elif settings[1] == '3.75':
			framerate = '15/3'
		else:
			framerate = '30/1'
		
		Gst.init(sys.argv)
		pipeline = Gst.Pipeline.new()
		pipeline = Gst.parse_launch('tcamsrc num-buffers=' + str((filmDuration * 30)) +' serial=4810628 '
					+ '! tcamautoexposure '
					+ '! tcamwhitebalance '
					+ '! tcamautofocus '
					+ '! video/x-bayer,format=bggr,width=1024,height=768,framerate=' + framerate + ' '
					+ '! capssetter join=false caps="video/x-bayer,format=gbrg" '
					+ '! bayer2rgb '
					+ '! videoconvert '
					+ '! omxh264enc '
					+ '! mp4mux '
					+ '! filesink location=' + filepath + 'Videoer/' + currentTime + '.mp4 ')
		pipeline.set_state(Gst.State.PLAYING)
		
		time.sleep(filmDuration + 0.5)
		
		pipeline.set_state(Gst.State.NULL)
		
		recorded.put(currentTime)
		print(currentTime + " enqueuet")

def read():
	global detectionPhase
	global filepath
	
	while(True):
		if not recorded.empty():
			videoName.value = recorded.get()
			datetime_object = datetime.strptime(videoName.value, "%d-%m-%Y_%H-%M-%S")
			capture = cv2.VideoCapture(filepath + "Videoer/" + videoName.value + ".mp4")
			
			frameNumber = 0
			detectFrameCount = 0
			referenceImageSaved = False
			
			while(capture.isOpened()):
				ret, frame = capture.read()
				
				if ret == False:
					break
				
				frameTime = datetime_object + timedelta(seconds=frameNumber / 30)
				
				if analyse(frame) == 1:
					if detectionPhase == False:
						print("!!!!!!!!!!! DETECTION !!!!!!!!!!!")
						startTime = frameNumber
						frameMarked = copy.deepcopy(frame)
						
						cv2.putText(frame, settings[6] + " " + frameTime.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,0), 2)
						cv2.putText(frame, settings[6] + " " + frameTime.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255))
						cv2.imwrite(filepath + "Detections/Pictures/" + str(frameTime.strftime("%d-%m-%Y_%H-%M-%S")) + ".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
						
						frameMarked = cv2.drawContours(frameMarked, contourList, -1, (0,0,255), 2)
						cv2.putText(frameMarked, settings[6] + " " + frameTime.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,0), 2)
						cv2.putText(frameMarked, settings[6] + " " + frameTime.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255))
						cv2.imwrite(filepath + "Detections/Pictures/" + str(frameTime.strftime("%d-%m-%Y_%H-%M-%S")) + "_marked.jpg", frameMarked, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
						detectionPhase = True
					elif detectionPhase == True and frameNumber == (filmDuration * int(settings[1])) - 2:
						stopTime = frameNumber
						print("start " + str(startTime) + " slutt " + str(stopTime))
						trim(startTime, stopTime)
						print("AVBRYTER PGA SLUTT AV FILM!###########")
						detectionPhase = False
					elif detectionPhase == True:
						print(str(frameNumber) + " Currently in detectionPhase, not storing a new startTrim")
						detectFrameCount = 0		
				else:
					if detectionPhase == False:
						print(str(frameNumber) + "No detection")
						if referenceImageSaved == False and frameNumber >= 30:
							cv2.imwrite(filepath + "reference.jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
							referenceImageSaved = True
					elif detectionPhase == True and frameNumber == (filmDuration * int(settings[1])) - 2:
						stopTime = frameNumber
						print("start " + str(startTime) + " slutt " + str(stopTime))
						trim(startTime, stopTime)
						print("AVBRYTER PGA SLUTT AV FILM!###########")
						detectionPhase = False
					elif detectionPhase == True:
						if detectFrameCount == 0:
							stopTime = frameNumber
						
						print(str(detectFrameCount) + " detectFrameCount")
						
						detectFrameCount += 1
						
						if detectFrameCount == 30:
							print("start " + str(startTime) + " slutt " + str(stopTime))
							trim(startTime, stopTime)
							detectionPhase = False
							detectFrameCount = 0
						
				frameNumber += 1

			capture.release()
			cv2.destroyAllWindows()
			
			print("ferdig read")
			
			#upload()
			
			os.system("rm -f " + filepath + "Videoer/" + str(videoName.value) + ".mp4")
		
def analyse(frame):
	'''
	hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
	#cv2.imshow("HSV Image", hsv)
	#cv2.waitKey(1)
	
	hue ,saturation ,value = cv2.split(hsv)
	cv2.imshow("saturation", saturation)
	cv2.waitKey(1)
	cv2.imshow("hue", hue)
	cv2.waitKey(1)
	cv2.imshow("value", value)
	cv2.waitKey(1)
	'''
	
	grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	retval, threshold = cv2.threshold(grayFrame, 30, 255, cv2.THRESH_BINARY)
	medianFiltered = cv2.medianBlur(threshold, 3)
	
	maskMultiply = cv2.bitwise_and(medianFiltered, thresholdMask.value)
	
	_, contours, hierarchy = cv2.findContours(maskMultiply, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
	
	contourList[:] = []
	for contour in contours:
		area = cv2.contourArea(contour)
		#if area > 50 and area < 300:
		if area > 50:
			contourList.append(contour)
	
	if not contourList:
		return 0
	else:
		return 1

def trim(startTime, stopTime):
	global filepath
	
	datetime_object = datetime.strptime(videoName.value, "%d-%m-%Y_%H-%M-%S")
	filename = datetime_object + timedelta(seconds=startTime / 30)
	
	capture = cv2.VideoCapture(filepath + "Videoer/" + str(videoName.value) + ".mp4")
	#fourcc = cv2.VideoWriter_fourcc(*'X264')
	# 0x00000021		funker fint, liten filstørrelse
	# 0x0000006c
	out = cv2.VideoWriter(filepath + "Detections/Trims/" + str(filename.strftime("%d-%m-%Y_%H-%M-%S")) + ".mp4", 0x00000021, 30.0, (1024,768))
	
	count = 0
	while(capture.isOpened()):
		ret, frame = capture.read()
		
		if ret == False:
			break
		
		timeOverlay = datetime_object + timedelta(seconds=count / 30)
		
		cv2.putText(frame, settings[6] + " " + timeOverlay.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,0), 2)
		cv2.putText(frame, settings[6] + " " + timeOverlay.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255))
		
		if(count >= (startTime - (int(settings[2]) * 30)) and count <= (stopTime + (int(settings[3]) * 30))):
			out.write(frame)
			
		count += 1
		
	capture.release()
	out.release()
	cv2.destroyAllWindows()
	print("ferdig trim")

def upload():
	global filepath
	
	for picture in os.listdir(filepath + "Detections/Pictures"):
		p = subprocess.Popen(["scp", filepath + "Detections/Pictures/" + picture, "hessfiles2@freja.hiof.no:/files/hessfiles2/test"])
		sts = os.waitpid(p.pid, 0)
	
	for trim in os.listdir(filepath + "Detections/Trims"):
		p = subprocess.Popen(["scp", filepath + "Detections/Trims/" + trim, "hessfiles2@freja.hiof.no:/files/hessfiles2/test"])
		sts = os.waitpid(p.pid, 0)
	
	'''
	if upload success:
		os.system("rm -f Detections/Pictures/*")
		os.system("rm -f Detections/Trims/*")
	'''

if __name__ == "__main__":
	m = Manager()
	settings = m.dict() #mulig gjør om til list og fjern currentLine variabelen i settings()
	recorded = m.Queue()
	videoName = m.Value('c', "")
	frameSave = m.Value('c', "")
	frameSaveMarked = m.Value('c', "")
	thresholdMask = m.Value('c', "")
	contourList = m.list()
	
	settingsProcess = Process(target=getSettings)		
	settingsProcess.start()
	settingsProcess.join()
	
	recordProcess = Process(target=record)
	readProcess = Process(target=read)
	
	recordProcess.start()
	readProcess.start()
	recordProcess.join()
	readProcess.join()
	
	recordProcess.terminate()
	readProcess.terminate()
