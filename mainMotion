#!/usr/bin/env python3

import cv2
import numpy as np
import time
import os
import math
import sys
import gi
from datetime import datetime, timedelta
from multiprocessing import *
import subprocess
import copy

gi.require_version("Tcam", "0.1")
gi.require_version("Gst", "1.0")

from gi.repository import Tcam, Gst

filmDuration = 15 # Seconds
filepath = "/home/nvidia/Bachelor/"
detectionPhase = False
previousFrame = None

def getSettings():
	global filepath
	
	f = open(filepath + "config.txt", "r")
	
	for line in f:
		settings.append(line.strip("\n"))
	f.close()
	'''
	0: Seconds saved before detection, 1: Seconds saved after detection, 2: Minimum object size for detection, 3: Maximum object size for detection,
	4: Number of frames before updating reference picture, 5: Number of frames containing a detection before start recording,
	6: Number of frames not containing a detection before stop recording, 7: Text overlay
	'''
	
	mask = cv2.imread(filepath + "mask.png")
	grayMask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
	retvalMaskTemp, thresholdMaskTemp = cv2.threshold(grayMask, 0, 255, cv2.THRESH_BINARY_INV)
	thresholdMask.value = thresholdMaskTemp
	
def record():
	global filepath
	
	while(True):
		currentTime = datetime.now().strftime("%d-%m-%Y_%H-%M-%S")
		
		Gst.init(sys.argv)
		pipeline = Gst.Pipeline.new()
		pipeline = Gst.parse_launch('tcamsrc num-buffers=' + str((filmDuration * 30)) +' serial=4810628 '
					+ '! tcamautoexposure '
					+ '! tcamwhitebalance '
					+ '! tcamautofocus '
					+ '! video/x-bayer,format=bggr,width=1024,height=768,framerate=30/1'
					+ '! capssetter join=false caps="video/x-bayer,format=gbrg" '
					+ '! bayer2rgb '
					+ '! videoconvert '
					+ '! omxh264enc '
					+ '! mp4mux '
					+ '! filesink location=' + filepath + 'Videoer/' + currentTime + '.mp4 ')
		pipeline.set_state(Gst.State.PLAYING)
		
		time.sleep(filmDuration + 0.5)
		
		pipeline.set_state(Gst.State.NULL)
		
		recorded.put(currentTime)
		print(currentTime + " enqueuet")

def read():
	global detectionPhase
	global filepath
	
	while(True):
		if not recorded.empty():
			videoName.value = recorded.get()
			datetime_object = datetime.strptime(videoName.value, "%d-%m-%Y_%H-%M-%S")
			capture = cv2.VideoCapture(filepath + "Videoer/" + videoName.value + ".mp4")
			
			frameNumber = 0
			detectStartCount = 0
			detectEndCount = 0
			while(capture.isOpened()):
				ret, frame = capture.read()
				
				if ret == False:
					break
				
				frameTime = datetime_object + timedelta(seconds=frameNumber / 30)
								
				if analyse(frame, frameNumber) == 1:
					if detectionPhase == False:
						startFrame = frame
						startTime = frameNumber
						detectionPhase = True
						print("FIKK EN 1'ER OG NÅ HUSKER VI STARTFRAME :)")
					elif detectionPhase == True and detectStartCount == settings[5]:
						print("!!!!!!!!!!! DETECTION !!!!!!!!!!!")
						
						cv2.putText(startFrame, settings[7] + " " + frameTime.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,0), 2)
						cv2.putText(startFrame, settings[7] + " " + frameTime.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255))
						cv2.imwrite(filepath + "Detections/Pictures/" + str(frameTime.strftime("%d-%m-%Y_%H-%M-%S")) + ".jpg", startFrame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
						
						for contour in contourList:
							(x, y), radius = cv2.minEnclosingCircle(contour)
							cv2.circle(frame, (int(x), int(y)), int(radius), (0, 0, 255), 2)
						cv2.imwrite(filepath + "Detections/Pictures/" + str(frameTime.strftime("%d-%m-%Y_%H-%M-%S")) + "_marked.jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
					elif detectionPhase == True and frameNumber == (filmDuration * 30) - 2 and detectStartCount >= settings[5]:
						stopTime = frameNumber
						print("start " + str(startTime) + " slutt " + str(stopTime))
						trim(startTime, stopTime)
						print("AVBRYTER PGA SLUTT AV FILM!###########")
						detectionPhase = False
					elif detectionPhase == True:
						print(str(frameNumber) + " Currently in detectionPhase, not storing a new startTrim")
						detectEndCount = 0
					
					print("detection start count " + str(detectStartCount))
					detectStartCount += 1					
				else:
					if detectionPhase == False:
						print(str(frameNumber) + "No detection")
					elif detectionPhase == True and frameNumber == (filmDuration * 30) - 2 and detectStartCount >= settings[5]:
						stopTime = frameNumber
						print("start " + str(startTime) + " slutt " + str(stopTime))
						trim(startTime, stopTime)
						print("AVBRYTER PGA SLUTT AV FILM!###########")
						detectionPhase = False
						
					elif detectionPhase == True:
						if detectEndCount == 0:
							stopTime = frameNumber
						
						print(str(detectEndCount) + " detectEndCount")
						
						if detectStartCount <= settings[5]:
							detectStartCount = 0
							detectionPhase = False
						
						if detectEndCount == settings[6]:
							print("start " + str(startTime) + " slutt " + str(stopTime))
							trim(startTime, stopTime)
							detectionPhase = False
							detectStartCount = 0
							detectEndCount = 0
						
						detectEndCount += 1
						
					print("detection start count " + str(detectStartCount))
				
				frameNumber += 1

			capture.release()
			cv2.destroyAllWindows()
			
			print("ferdig read")
			
			#upload()
			
			#os.system("rm -f " + filepath + "Videoer/" + str(videoName.value) + ".mp4")
		
def analyse(frame, frameNumber):
	global previousFrame
	
	if previousFrame is None:
		previousFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
		previousFrame = cv2.GaussianBlur(previousFrame, (3, 3), 0)
		return 0
	
	gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	gray = cv2.GaussianBlur(gray, (3, 3), 0)
	
	frameDelta = cv2.absdiff(previousFrame, gray)
	thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]
	
	thresh = cv2.bitwise_and(thresh, thresholdMask.value)
	
	thresh = cv2.dilate(thresh, None, iterations=2)
	
	_, contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
	
	contourList[:] = []
	for contour in contours:
		if cv2.contourArea(contour) > settings[2] and cv2.contourArea(contour) < settings[3]:
			contourList.append(contour)
	
	if frameNumber % settings[4] == 0:
		previousFrame = gray
	
	if not contourList:
		return 0
	else:
		return 1

def trim(startTime, stopTime):
	global filepath
	
	datetime_object = datetime.strptime(videoName.value, "%d-%m-%Y_%H-%M-%S")
	filename = datetime_object + timedelta(seconds=startTime / 30)
	
	capture = cv2.VideoCapture(filepath + "Videoer/" + str(videoName.value) + ".mp4")
	#fourcc = cv2.VideoWriter_fourcc(*'X264')
	# 0x00000021		funker fint, liten filstørrelse
	# 0x0000006c
	out = cv2.VideoWriter(filepath + "Detections/Trims/" + str(filename.strftime("%d-%m-%Y_%H-%M-%S")) + ".mp4", 0x00000021, 30.0, (1024,768))
	
	count = 0
	while(capture.isOpened()):
		ret, frame = capture.read()
		
		if ret == False:
			break
		
		timeOverlay = datetime_object + timedelta(seconds=count / 30)
		
		cv2.putText(frame, settings[7] + " " + timeOverlay.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,0), 2)
		cv2.putText(frame, settings[7] + " " + timeOverlay.strftime("%d/%m/%Y %H:%M:%S"), (2,762), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255))
		
		if(count >= (startTime - (int(settings[0]) * 30)) and count <= (stopTime + (int(settings[1]) * 30))):
			out.write(frame)
			
		count += 1
		
	capture.release()
	out.release()
	cv2.destroyAllWindows()
	print("ferdig trim")

def upload():
	global filepath
	
	for picture in os.listdir(filepath + "Detections/Pictures"):
		p = subprocess.Popen(["scp", filepath + "Detections/Pictures/" + picture, "hessfiles2@freja.hiof.no:/files/hessfiles2/test"])
		sts = os.waitpid(p.pid, 0)
	
	for trim in os.listdir(filepath + "Detections/Trims"):
		p = subprocess.Popen(["scp", filepath + "Detections/Trims/" + trim, "hessfiles2@freja.hiof.no:/files/hessfiles2/test"])
		sts = os.waitpid(p.pid, 0)
	
	'''
	if upload success:
		os.system("rm -f Detections/Pictures/*")
		os.system("rm -f Detections/Trims/*")
	'''

if __name__ == "__main__":
	m = Manager()
	settings = m.list()
	recorded = m.Queue()
	videoName = m.Value('c', "")
	frameSave = m.Value('c', "")
	frameSaveMarked = m.Value('c', "")
	thresholdMask = m.Value('c', "")
	contourList = m.list()
	
	settingsProcess = Process(target=getSettings)		
	settingsProcess.start()
	settingsProcess.join()
	
	recordProcess = Process(target=record)
	readProcess = Process(target=read)
	
	recordProcess.start()
	readProcess.start()
	recordProcess.join()
	readProcess.join()
	
	recordProcess.terminate()
	readProcess.terminate()
